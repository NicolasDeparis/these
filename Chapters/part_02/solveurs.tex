\chapter{Les principaux moteurs physiques}
\label{sec:solvers}

%Nous allons voir dans cette partie que plus une physique représente une part importante du contenu de l'Univers plus elle est simple et rapide a simuler.

L'Univers est modélisé par différents "fluides" (cf section \ref{cosmoparam}) et l'objectif des simulations numériques est d'estimer au mieux leurs évolutions, en fonctions des lois auxquelles ils sont soumis et de leurs états à un instant donné.
La résolution de chacun de ces systèmes sera confiée à différents "moteur", ayant pour tâche de résoudre les systèmes d'équations différentielles gouvernant les différentes physiques.
Lors de la réalisation d'une simulation, la grande majorité des ressources de calculs sera utilisée par ces moteurs.
%Les trois moteurs que nous allons aborder ont pour objectif de suivre des système dont l'évolution est régie par un système d'équations différentielles.

L'objectif de cette partie est de présenter les différentes techniques et implémentations des moteurs physiques de EMMA.
Nous allons détailler ses trois principaux moteurs  :
\begin{itemize}
\item le moteur gravitationnel,
\item le moteur hydrodynamique,
\item le moteur radiatif.
\end{itemize}

%Il va être nécessaire de discrétiser ces systèmes avant de pouvoir les traiter numériquement 


%\section{Génération des conditions initiales}
%\label{sec:IC}
%
%La première étape consiste à déterminer l'état initial du système que l'on cherche à résoudre.
%Nous avons vu (cf \ref{sec:CMB}) que le \ac{CMB} nous donne de l'information sur l'état de la distribution de matière dans l'univers très tôt dans son histoire.
%Il est possible de déterminer le spectre de puissance des fluctuations de densité de l'univers primitif à partir du \ac{CMB}.
%Le principe de la génération des condition initiales est d'utiliser ce spectre de puissance pour générer des surdensité représentant statistiquement ces fluctuations.
%Pour se faire on va générer une grille régulière sur laquelle on placera une particule au centre de chaque cellule, dans ce cas la densité est homogène.
%On va alors perturber la position des particules de manière à respecter les fluctuations statistique observées dans le \ac{CMB}.
%Pour ce faire, on va générer un bruit aléatoire Gaussien que l'on 
%%Tout les générateurs de condition initiales que j'ai pu rencontrer utilise une SEED aléatoire, dans le but de générer ce bruit aléatoire.
%convoluera ensuite avec le spectre de puissance que l'on cherche a reproduire.
%On déplacera finalement les particules en accord en leurs appliquant les perturbations obtenues. 
%Cette approximation est l’approximation de Zeldovitch (voir eg \cite{2014MNRAS.439.3630W}) et n'est valable que dans le cas des petites perturbations, tant que l'on reste dans le régime linéaire.
%%L’approximation de Zeldovitch est capable de prédire analytiquement la distribution de la matière à très grandes échelles.
%%Mais plus l'on cherche à étudier des petites échelles, plus on sort vite du domaine de précision acceptable.
%En dehors de cette approximation, il est nécessaire d'avoir recourt aux simulations numériques.
%
%Nous voyons ici que le spectre est limité des deux cotés.
%D'un coté l'information des grandes échelles est tronquée par la taille de la boite considéré et il n'est pas possible d'avoir de l’information sur des longueurs d'onde du spectre plus grande que cette taille limite.
%De l'autre coté, les petites échelles sont tronquées par la limite de résolution et le spectre est troqué au niveau de la longueur d'onde correspondant à la résolution de la grille.
%Cette perte d'information sur les hautes fréquences peux être problématique dans le cas où la résolution est adaptative.
%%Dans le cas de l'\ac{AMR} par exemple il peux paraître difficile d'autoriser un nombre élevé de niveau de raffinement puisque les niveaux nouvellement créer ne disposerons pas de l'information des conditions initiales.
%
%En pratique j'ai principalement utilisé MUSIC \citep{hahn_multi-scale_2011} et GRAPHIC \citep{2008ApJS..178..179P}.

%méthode
%gaussian random noise
%théorie des perturbation linéaire
%lien avec le spectre de puissance
%MUSIC et GRAPHIC
%limite la résolution min et max (min en masse et max en espace)


%une simulation est limité par sa taille et sa résolution -> ceci définit la plage d'échelle que l'on peut simuler
%
%principes de bases ennoncé dans Pen (1997) and Bertschinger (2001).
%
%    discrétisation de l'espace
%    placement des particules sur la grille
%    génération d'un bruit blanc
%    convolution avec un spectre de puissance connu (celui du CMB)

%
%\subsection{Théorie des perturbation linéaire}
%
%approximation de zeldovich
%perte de linéarité a un certain moment -> nécessité des simulation numériques


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Gravitation et matière noire}
\label{sec:solverDM}

La matière noire, dispose de propriétés de fluide non collisionel, et se prête particulièrement bien à la représentation Lagrangienne, et donc à une simulation sous forme de particules.
Pour la simuler, on utilisera le principe des code N-corps., c'est à dire qu'on utilisera un champs de particules massives interagissantes uniquement par gravitation.
Il existe différentes techniques pour suivre l'évolution d'un tel système, toutes sont basées sur le même principe.
Les particules sont placées suivant une certaine condition initiale et on cherche à connaître la force gravitationnelle à laquelle chaque particule est soumise, dans le but de calculer son déplacement.


%\subsection{Moteur de gravité}
%\label{sec:gravity}

%Je vais plus détailler le solveur de gravité que les autres puisque c'est celui sur lequel j'ai le plus travaillé.
%Le sloveur que je connais le mieux.
%Fluide non collisionnel -> particule\\

%On cherche à suivre dynamiquement l'évolution de particules a partir d'une conditions initiales.
%Le but est d'obtenir la position des particules à chaque instant.
%Pour cela, il faut leurs vitesses.
%Pour cela, il faut leurs accélération.
%Pour cela, il faut la force qui leur est appliquée.
%Et dans certain cas, il faut le potentiel gravitationnel.
Pour ce faire on utilise le système d'équation suivant:

\begin{equation}
\begin{cases}
\frac{d\vec{x}_p}{dt} = \vec{v}_p, \\
\frac{d\vec{v}_p}{dt} = -\nabla \phi , \\
\Delta \phi= 4\pi G \rho,
\end{cases}
\label{eq:Ncorps}
\end{equation}
où ${x}_p$ représente la position de la particule, $\vec{x}$ sa vitesse et et $\phi$ le potentiel gravitationnel, fonction de la densité $\rho$.

Il existe plusieurs méthodes pour résoudre ce système.
%Historiquement la première méthode était la méthode
\paragraph{Particule-Particule : } c'est la méthode la plus directe pour calculer l'évolution d'un system N-corps. 
Elle consiste, pour chaque particule, à sommer les contributions gravitationnelles de toutes les autres particules:
\begin{equation}
\vec{F}_i=-\sum_{j\neq i} G \frac{G m_i m_j(\vec{r}_i - \vec{r}_j) }{ |\vec{r}_i - \vec{r}_j |^3}
\end{equation}
Ce type de code dispose d'une très bonne précision mais la quantité de calculs évolue en ordre $O(N^2)$, ce qui les rends très coûteux.

%Une évolution de cette méthode est la méthode :
\paragraph{Tree code: } évolution de la méthode Particule-Particule, elle consiste à regrouper les particules les plus lointaine de la particule courante en amas ayant une interaction gravitationnelle commune \citep{1986Natur.324..446B}.
% (Barnes & Hut 1986) 
Cette approximation permet de limiter le nombre de calcul à l'ordre $O(n log n)$. %, pour les interactions lointaine qui sont de toute façons faibles 

%On peux obtenir cette force soit par calcul direct, soit par dérivation du potentiel.
%
%\begin{equation}
%\vec{F}=-\Delta \Phi
%\end{equation}


\paragraph{Particule-Mesh (PM) : } La méthode qui nous intéresse ici.
Elle consiste à ne plus calculer directement la force, mais à la dériver à partir du potentiel, lui même calculé sur une grille.
En projetant les particules sur une grille, on obtient une grille de densité utilisée pour obtenir le potentiel en résolvant l'équation de Poisson.

\paragraph{}
La méthode de projection des particules sur la grille n'est pas unique.
A l'ordre $0$, il est possible de se contenter d'ajouter la masse de la particule dans la cellule a laquelle elle appartient.
On utilisera en pratique une méthode d'ordre supérieur appelée \ac{CIC}, qui consiste à considérer une étendue spatiale cubique aux particules et à pondérer la masse appliquée aux cellules par l'intersection de son volume et de celui de la cellule (voir Fig\,\ref{fig:CIC}).
On associe généralement une taille à la particule similaire à celle des cellule sur laquelle on la projette.
Dans le cas où l’étendue de la particule intersecte des cellules de différents niveaux on lui associera la taille de la plus grande cellule dans le but de lisser la transition entre les niveaux.
%TODO schéma ?
%Il existe des méthodes d'ordre supérieur avec des kernel plus complexe que le top-hat du \ac{CIC} comme par exemple des kernel en triangle ou en gaussienne.
%http://techfinder.stanford.edu/technology_detail.php?ID=30866

\begin{figure}
		\centering
        \includegraphics[width=.5\linewidth]{img/02/CIC.jpg} 
        \caption[CIC]{Représentation en 2D du Cloud In Cell. 
        La masse d'une particule est répartie dans le cellules environnantes en lui associant une étendue spatiale.
        %http://homepage.univie.ac.at/franz.vesely/cp_tut/nol2h/new/c6sm_s4lr.html
 		\label{fig:CIC}}
\end{figure}


\subsection{Résolution de l'équation de Poisson}

%Une fois la grille de densité générée, nous pouvons calculer le potentiel en résolvant l'équation de Poisson.

%\begin{equation}
%\Delta \Phi = S_{(\rho)}
%\end{equation}
%
%où :
%\begin{equation}
%S_{(\rho)} = 4 \pi G \rho
%\end{equation}
%dans le cas classique, et devient en système d'unité supercomobile (cf Sec. \ref{sec:supercomobil}):
%\begin{equation}
%S_{(\rho)} = 6 a \delta_{(\rho)}
%\end{equation}
%avec le contraste de densité: 
%\begin{equation}
%\delta_{(\rho)} = \rho / < \rho > - 1 
%\end{equation}
%
%En intégrant deux fois la distribution de densité on obtient le potentiel gravitationnel:
%
%\begin{equation}
%\Delta \phi = S \longrightarrow \phi = \iint \Delta \phi = \iint S_{(\rho)}
%\end{equation}


%Pour cela, il existe principalement deux types de méthodes. 
%La première est basée sur les transformées de Fourier. 
%Cette méthode, très rapide, utilise le fait que dans l'espace de Fourier, une intégrale se résume à une division par un nombre d'onde. 
%Déterminer le champ de potentiel revient à : 
%\begin{itemize}
%\item Effectuer la transformée de Fourier de la densité
%\item Diviser par $k^2$
%\item Effectuer la transformée de Fourier inverse
%\end{itemize}
%
%\begin{equation}
%S_{(\vec{x})} \overset{FFT}{\longrightarrow}  S_{(\vec{k})} \times \frac{1}{k^2}  \overset{RFFT}{\longrightarrow}  \phi_{(\vec{x})}
%\end{equation}
%
%De par la nature des transformées de Fourier, le champ de densité doit être périodique pour que l'implémentation de cette technique ne se révèle pas trop complexe. 
%Ce qui n'est pas un problème en simulation cosmologique, où les conditions de bords sont toujours périodiques mais est plus problématique lors de la simulation de structures isolées, telles les galaxies ou les amas de galaxies. 
%De plus, les \ac{FFT} nécessitent un échantillonnage régulier, ce qui implique que cette méthode est incompatible avec les méthodes \ac{AMR}. 
%%Et dernièrement, le passage dans l'espace des fréquences nécessite des conditions de types plans parallèles lors parallélisation, conditions incompatible avec la gestion de grille utilisé par les code AMR dont EMMA} fait partie. \\


Connaissant la distribution de densité à un instant donné, il est possible de calculer le potentiel gravitationnel en résolvant l'équation de Poisson.

Il existe plusieurs méthodes dédiées à la résolution ce problème.
EMMA utilise une méthode itérative consistant à faire converger le potentiel gravitationnel à partir d'une grille de densité initiale arbitraire. 
Ces méthodes permettent d'utiliser tout type de conditions de bords, sont facilement parallélisable et sont compatible avec les méthodes basées sur des grilles adaptatives.
%Par la suite, c'est donc une méthode itérative et plus précisément une méthode \emph{Multigrille} qui à été développée.
%Le potentiel est alors dérivé pour obtenir la force ressentie dans chaque cellule. 
%Il est ensuite aisé de calculer l'accélération subie par les particules de chaque cellule, et par intégration temporelle, leurs nouvelles positions et vitesses.
Le principe de ces méthodes est d'introduire un terme temporel fictif et de rechercher un solution stationnaire à cette nouvelle équation.
Par analogie à l'équation de la chaleur par exemple : la densité correspond aux sources chaudes et le potentiel à la température, à $t=0$ les sources chaudes sont allumées et la chaleur se propage jusqu'à ce que le milieu ait atteint sa température d'équilibre. 
%Ici, c'est la gravité qui se diffuse dans le milieu.
L'équation à résoudre est donc:

\begin{equation}
\dfrac{\partial \phi}{\partial t} = \Delta \Phi -S_{(\rho)}
\end{equation}

La méthode de Jacobi est la façon la plus simple de relaxer ce type d'équation, elle consiste à utiliser la forme discrète de l'équation de Poisson modifiée. 
L'équation à intégrer est:

\begin{equation}
\dfrac{\phi^{t+1}_i - \phi^{t}_i}{\Delta t}  =  \Delta \phi_i^t - S_i^t
\end{equation}

où, à 1 dimensions, le Laplacien sera discrétisé de la manière suivante :

\begin{equation}
\Delta \phi_i^t = \dfrac{\phi_{x+1}^t  + \phi_{x-1}^t- 2\phi_{x}^t}{\Delta x ^2}
\end{equation}
		
%Le principal avantage de cette méthode est qu'elle ne nécessite de connaître l'état du système qu'au temps $t$.

%Ainsi, chaque fils d'exécution parallèle (thread) est indépendant et n'a pas d'information à communiquer aux autres.
Cette méthode est itérée jusqu'à ce que soit le potentiel ait convergé, soit un nombre maximal d'itération soit atteint.

Il est possible d'augmenter la vitesse de convergence en utilisant la méthode de Gauss-Seidel.
Elle consiste à toujours utiliser la valeur la plus à jour disponible:
%Au lieu d'utiliser, à chaque pas de temps, les valeurs de la grille au niveau précédent, cette méthode consiste à toujours utiliser la valeur la plus à jour disponible. 
%Une fois $\phi^{t+1}_0$ calculé à l'aide de $\phi^{t}_i$, la valeur de $\phi^{t+1}_1$ n'est pas calculée à l'aide de $\phi^{t}_0$ mais avec $\phi^{t+1}_0$. 
%En utilisant toujours la valeur la mieux estimée, cette méthode accélère la convergence. 
%L'intégration temporelle ne change pas, mais l'intégration spatiale devient: 
\begin{equation}
\Delta \phi_i^t = \dfrac{\phi_{x+1}^t  + \phi_{x-1}^\mathbf{t+1}- 2\phi_{x}^t}{\Delta x ^2}
\end{equation}

En pratique on utilisera la méthode dite Gauss-Seidel rouge-noir.
Elle consiste à séparer la grille en un damier de deux couleurs, une première itération sera réalisé seulement sur la partie rouge, puis une seconde itération sera réalisée sur la partie noire en prenant en compte le nouvel état de la partie rouge. 
L'avantage du Gauss-Seidel rouge-noir est que le calcul de chaque demi-domaine peut parallélisé, ce qui n'est pas le cas avec la technique Gauss-Seidel classique.

%La parallélisation de cette méthode est plus compliquée que dans le cas de Jacobi. 
%La détermination de la valeur de chaque cellule nécessite de connaître l'état le plus à jour de ses voisins et donc de faire passer de l'information entre les processus.
%Cependant, une méthode nommée Gauss-Seidel Rouge-Noir facilite la parallélisation en séparant l'espace en un damier de couleurs. 
%%Chaque processeur ne calcule alors qu'une seule couleur. 
%Le premier processeur calcul par exemple les cases blanches de l'échiquier à partir de $\phi_i^t$, puis le second calcul le cases noires à partir des cases blanches déterminé par le premier.
%
%
%\subsubsection{Sur-relaxation successive (SOR)}
%La méthode de sur-relaxation successive consiste à appliquer un coefficient pour sur-estimer l'évolution de la convergence et ainsi l'accélérer. 
%L'équation à intégrer devient:
%\[ \phi^{t+1}_i = \phi^{t}_i + \omega  \Delta t \left (\Delta \phi_i^t -S^t_i \right )  \]
%où $\omega \in \left] 0,2 \right [$ est le paramètre de sur-relaxation.
%\begin{itemize}
%\item lorsque $\omega <1$ La méthode est dite de sous relaxation.
%\item lorsque $\omega =1$ La méthode devient celle de Gauss-Seidel.
%\item lorsque $\omega >1$ La méthode est dite de sur relaxation.
%\end{itemize}
%Il existe des moyens analytiques pour déterminer la valeur optimale de $\omega$ mais très souvent cette valeur est déterminée empiriquement à partir d'une série de tests. 
%$\omega = 1,2$ est très souvent utilisé.
%%L'expression de cette méthode apparait généralement dans la litterature sous la forme:


%\subsubsection{Condition d'arrêt}
%Ces méthodes sont itérées jusqu'à ce qu'un certain critère convergence soit respecté. 
%Le critère le plus couramment utilisé consiste à mesurer l'évolution de la convergence en comparant sa valeur au temps $t$ à celle au temps $t+1$.
%\[ \phi^{t+1}_i - \phi^{t}_i < \epsilon \]
%ou, de manière équivalente:
%\[ \Delta \phi_i^t - S_i^t< \epsilon \]
%
%Pour prendre en compte la possibilité que le potentiel ait convergé sur une partie du domaine seulement, et pour ne pas stopper le processus trop tôt, c'est le module de cette expression qui est considéré. 
%De plus il est d'usage de normaliser ce module par la source que l'on considère.
%
%\[\dfrac{ \sqrt{  \sum_i \left (  \Delta \phi_i^t \right )^2 - \left (S^t_i  \right )^2 } }{\sqrt{  \sum_i  \left (S^t_i  \right )^2 } } < \epsilon \]
%
%A cette condition est ajouté un nombre d'itérations maximum fixe pour éviter les problèmes de boucles infinies lorsque le potentiel n'arrive pas à converger (oscillation autour d'une valeur d'équilibre par exemple).

\subsection{Multigrille}

La technique du multigrille a été développée pour améliorer la vitesse de convergence des méthodes itératives.
Elle consiste à utiliser le fait que ces dernières convergent rapidement sur les petites échelles spatiales et plus lentement sur les grandes échelles.% en utilisant une série de grilles à différentes résolutions.
%De plus elles considère non plus la grandeur elle même, mais l'erreur effectuée dans l'estimation de cette grandeur.

%L'équation à résoudre est alors modifiée en considérant que l'inconnue n'est plus le potentiel mais l'erreur commise sur son estimation. 
%Le terme source n'est plus la densité mais la densité moins son estimation grossière.
%
%Si l'équation à résoudre est de la forme : 
%\[ \mathcal{L} u = f \]
%Sa forme discrète est :
%\[ \mathcal{L}_h u_h = f_h \]
%si $\tilde{u_h}$ correspond à une estimation de la solution et $u_h$ à la solution exacte, l'erreur est alors la différence entre les deux : 
%\[ v_h = u_h - \tilde{u_h}. \]
%Le résidu est défini comme:
%\[ d_h = \mathcal{L}_h \tilde{u_h} - f_h \]
%
%Et en utilisant la linéarité de l'opérateur Laplacien:
%%comme $\mathcal{L}_h$ est linéaire:
%\[ \mathcal{L}_h u_h = \mathcal{L}_h (v_h + \tilde{u_h} ) = \mathcal{L}_h v_h +\mathcal{L}_h \tilde{u_h} \]
%\[ f_h   = \mathcal{L}_h \tilde{u_h} - d_h\]
%et finalement :
%\[ \mathcal{L}_h v_h = -d_h \]

Le cycle consiste à lisser (ie réaliser quelques itérations d'une méthode de résolution classique) le potentiel à pleine résolution, les hautes fréquences vont alors rapidement converger.
On va ensuite conserver cette information, et dégrader la grille à plus basse résolution (cf section \ref{sec_gridchange}).
%Il faut ensuite calculer une estimation de l'erreur commise à ce stade et la dégrader à plus basse résolution (cf section \ref{Opérateurs de changement de grilles}).
%elle ne contient alors que de l'information sur les basses fréquences de la grille de départ, les hautes fréquences de la grille à pleine résolution ont été supprimées par la dégradation. 
%Cette perte d'information sur les hautes fréquences n'est pas problématique car les hautes fréquences ont déjà convergé l'erreur est donc petite (voir nulle) aux hautes fréquence et est maximale aux basses.
%Les hautes fréquences de cette nouvelle grille correspondent alors à des échelles spatiales plus grandes que sur la grille précédente, et ces échelles sont donc maintenant plus faciles à faire converger. 
%et donc plus difficiles à faire converger sur le grille haute résolution. 
La solution exacte est alors calculée (relaxée jusqu'à convergence) sur cette seconde grille, cette dernière étant significativement plus petite que la grille départ, la résolution du potentiel est beaucoup plus rapide.
Cette solution à basse résolution est alors projetée à la résolution de la grille de départ, puis corrigée de l'information sur les hautes fréquence précédemment stockée.
Le cycle sera alors terminé par un lissage de quelques itérations.

%Le potentiel précédemment estimé est alors corrigé de l'erreur exacte projetée à pleine résolution, puis lissé par quelques dernières itérations.
Ce processus peut être utilisé récursivement pour générer tout un ensemble de sous-grilles et ainsi accélérer encore la convergence (cf figure \ref{fig:mgrid}).
En jouant sur le nombre d'appels récursifs de la fonction, il est possible de créer différentes géométries de cycles. 
Un seul appel génère un cycle nommé cycle en V, deux un cycle en W, etc... 
% en utilisant:
%\[ \tilde{u}_h^{new} = \tilde{u_h} + v_h \]

%TODO schéma

%Ce cycle peut être résumé ainsi:
%
%\begin{tabular}{ll}
%Lisser 		& 	$ \mathcal{L} u_h = f_h $\\
%Calculer	&	$ d_h = \mathcal{L}_h \tilde{u_h} - f_h $\\
%Restreindre	&	$ d_H = Rd_h$\\
%Résoudre	&	$ \mathcal{L} v_H = -d_H $\\
%Interpoler	&	$ v_h = Pv_H$\\
%Corriger	&	$ \tilde{u}_h^{new} = \tilde{u_h} + v_h$\\
%Lisser		&	$ \mathcal{L} u_h = f_h $
%\end{tabular} 
%A partir de la méthode deux grilles, rien n'empêche d'estimer l'erreur sur l'erreur par la même méthode, 



%L'algorithme devient alors:
%
%MG(level, $u_h$, $f_h$)
%\begin{itemize}	
%\item 	si level = level min:
%\item[]	\begin{tabular}{ll}
%		Résoudre & $\mathcal{L} u_h = f_h $
%		\end{tabular}
%\item 	sinon:
%\item[]	\begin{tabular}{ll}
%		Lisser 		& 	$ \mathcal{L} u_h = f_h $\\
%		Calculer	&	$ d_h = \mathcal{L}_h \tilde{u_h} - f_h $\\
%		Restreindre	&	$ d_H = Rd_h$\\
%		Appeler 	&	MG(level-1, $v_H$, $-d_H$) \\
%		Interpoler	&	$ v_h = Pv_H$\\
%		Corriger	&	$ \tilde{u}_h^{new} = \tilde{u_h} + v_h$\\
%		Lisser		&	$ \mathcal{L} u_h = f_h $
%		\end{tabular} 
%\end{itemize}
%
%Où "level" est le niveau de la grille. $h$ est le pas de la grille au niveau $L$ et $H = 2h$. 
%Les opérateurs $P$ et $R$ sont les opérateurs de prolongation et de restriction explicité section \ref{Opérateurs de changement de grilles}.


\begin{figure}
	\begin{center}
	\includegraphics[width=0.95\textwidth]{img/02/Vcycle2.png}
	\caption[Multigrille]{Vue du V-cycle et des différents niveaux de grilles.
	 S=lissage, R=restriction, A=calcul exact et P=prolongation.
	 Image extraite de \cite{multigrid}
	 \label{fig:mgrid}}
	\end{center}
\end{figure}	

%\begin{figure}[htbp]
%\begin{center}
%\includegraphics[scale=0.35]{img/02/Vcycle.png}
%\caption{\textbf{Description du V-cycle.} Image extraite de \href{http://MGNet.org}{MGNet.org}}
%\label{Description du V-cycle}
%\end{center}
%\end{figure}		

\subsection{Implémentation sur grille adaptative}

Dans EMMA, la potentiel est calculé par multigrille sur la grille de base. % et utilise l'arbre \ac{AMR} pour gérer les sous-niveaux.
Par contre sur les niveaux raffinés la relaxation est effectuée par Gauss Siedel rouge/noir. %, une amélioration de la méthode Jacobi classique.
La solution déterminée sur les niveaux grossiers est projetée sur les niveaux raffinés, la solution anticipée est donc déjà proche de sa vraie valeur et il en résulte une convergence rapide.

%Pour des raisons techniques, on prendra garde lors de calculs en parallèles, à utiliser un niveau minimum de telle sorte que chaque processeur dispose au minimum d'un OCT lors du calcul sur la grille la plus grossière du multigrille.
%Le niveau minimum du V-cycle sera exprimé par : 
%
%\begin{equation}
%L_{min} = 1 + ceil \left(\frac{log_2(N_{cpu})}{3}  \right) 
%\end{equation}


%\subsection{Liste chaînée de particule}
%\label{sec:chainepart}
%La gestion des particules dans EMMA utilise le principe de la liste chaînée déjà abordée pour les OCT. %TODO ref
%A chaque cellule est associée  un pointeur vers une particule de tète.
%Si ce pointeur est NULL, la cellule ne contient pas de particule.
%Les particules entrant dans cette cellule seront ajoutées a la liste chaînée.
%On prendra garde a gérer cette liste au moment du raffinement et du déraffinement des cellules.
%
%\subsection{Le pas de temps}
%
%Le pas de temps sera calculer de telle sorte a respecter la condition de Courant.
%Une particule ne doit pas se déplacer de plus d'une fraction de case a chaque pas de temps.


%	    dtloc=0.1*SQRT(2.*M_PI/(3.*(curoct->cell[icell].gdata.d+1.)*aexp));
%\begin{equation}
%
%\end{equation}

\subsection{Gestion du pas de temps}
\label{sec:dtgrav}

Pour assurer une résolution stable, il ne doit pas être possible pour une particule de se déplacer de plus d'une fraction $\epsilon$ de la taille d'une cellule $\Delta x$ par pas de temps.
Pour se faire, pas de temps sera définis comme:
\begin{equation}
\Delta t_{grav} = \epsilon \frac{\Delta x}{|v_{max}|},
\end{equation}
où $|v_{max}|$ représente la vitesse de la particule la plus rapide (de l'ordre de $100$ km.s$^{-1}$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\section{Hydrodynamique et la physique baryonique}
\label{sec:hydro}
%solveur hydro
%partie la plus intensive en calcul
%
%Le moteur hydrodynamique est certainement la partie du code la plus complexe et c'est aussi celle sur laquelle j'ai le moins travaillé.
%Je vais tout de même en exposer les grandes lignes, mais cette partie sera moins étoffée que celles des autres moteurs physiques.
%
%Comme nous l'avons vu plus tôt (cf \ref{sec:nucleosynthese_primordiale}), l'Univers est constitué d'une grande quantité d'hydrogène et d'hélium sous forme gazeuse.

Dans le cas de l'étude de l'\ac{EoR} la physique du gaz est centrale, car l'objectif est précisément de déterminer les propriétés physico-chimiques de ce gaz, et leurs impacts sur la formation des galaxies.
La physique du gaz, contrairement à celle de la matière noire, est collisionnelle et sera ici modélisé avec une approche Eulérienne (cf section \ref{ch:introduction}).
En première approximation, dans l'Univers le gaz est principalement soumis à deux effets : sa pression interne et la gravité.
Sa physique est régie par les équations d'Euler auto-gravitantes et le système à résoudre est :

\begin{equation}
\begin{cases}

{ \frac{ \partial \rho }{ \partial t } + \nabla \cdot (\rho \vec{v}) = 0}, \\
\\
{ \frac{ \partial }{ \partial t } (\rho \vec{v}) + \nabla \cdot (\rho \vec{v} \otimes v + P1\!\!1 )  = -\rho\nabla \phi }, \\
\\
{ \frac{ \partial E }{ \partial t } + \nabla \cdot [ \rho v (E+p)\vec{v} ] = -\rho \vec{v} \cdot \nabla \phi },

\end{cases}
\end{equation}
\label{eq:hydro}
%+ \rho^2 \Lambda
%$\Lambda$ est la fonction de refroidissement.

avec ;
la densité $\rho = \rho(\vec{x},t)$,
la vitesse $ \vec{v} = (u,v,w)^T$,
$P$ la pression, $E$ l’énergie totale, et $\Phi$ le potentiel gravitationnel.
Ce système exprime la conservation de la masse, de l'impulsion et de l'énergie.

Il nécessaire d'introduire une équation d'état pour fermer ce système.
Nous considérerons ici le cas d'un gaz parfait monoatomique, l'équation de fermeture sera donc:

%\begin{equation}
%P=(\gamma - 1) \rho \epsilon, 
%\end{equation}
%avec l'indice adiabatique $\gamma = 5/3$.
%
%L'énergie totale est donc :
\begin{equation}
E = \frac{\rho}{2}\vec{v}^2 + \frac{P}{\gamma -1}
\end{equation}
avec l'indice adiabatique $\gamma = 5/3$.


%\begin{equation}
%p=\rho k T, 
%\end{equation}
%avec $k=1.38064852 \cdot 10^{-23} \left[ \mathrm{m^2 \cdot kg \cdot s^{-2} \cdot K^{-1}} \right] $ la constante de Boltzmann.

%\begin{itemize}
%\item PDE
%\item IC
%\item BC
%\end{itemize}


%\begin{equation}
% \frac{\partial U}{\partial t} + \nabla \cdot (F(U)) = S(U), 
%\label{eq:rad_generale}
%\end{equation}
%
%avec $U$ le vecteur des quantité conservées, $F$ la fonction de flux, et $S$ le terme source. Pour la résolution du transport des photons (sans terme source), on retrouve :


En analyse numérique ce système sera réécrit sous la forme:

\begin{equation}
U_t+F_x(U) = S(U),
\label{eq:conservation}
\end{equation}
où les sous-scripts représentent les dérivées temporelles et spatiales.

Le vecteur des quantité conservées $U$, la fonction de flux $F(U)$, et le terme source $S(U)$ seront alors exprimés sous la forme :

\begin{equation}
\begin{array}{c}

U=
\left(
\begin{array}{c}
{ \rho}\\
{\rho u}\\
{\rho v}\\
{\rho w}\\
{\rho E}
\end{array}
\right),
\\
F(U)=
\left(
\begin{array}{ccc}
\rho u & \rho v & \rho w \\ 
\rho u^2 +P & \rho uv & \rho uw \\ 
\rho uv & \rho v^2 +P & \rho vw \\ 
\rho uw & \rho vw &\rho w^2 +P \\ 
(\rho \epsilon + P)u & (\rho \epsilon + P)v & (\rho \epsilon + P)w
\end{array} 
\right)
\\
S(U) =
\left(
\begin{array}{c}
{ 0}\\
{\rho \Phi_x}\\
{\rho \Phi_y}\\
{\rho \Phi_z}\\
{- \rho u \cdot \nabla \Phi + \Lambda }
\end{array}
\right),
\end{array} 
\end{equation}

où: $\Lambda = \Lambda_{(E,\rho)}$ est la fonction de refroidissement (cf section \ref{sec:refroidissement} et \ref{sec:chimie}).

%,
%F(U)=
%\begin{cases}
%{ \rho u}\\
%{ \rho u^2+p}\\
%{ \rho uv}\\
%{ \rho uw}\\
%{ u(E+p)}
%\end{cases}
\subsection{Problème de Riemann et volumes finis}

L'idée de base du moteur hydrodynamique est de décomposer le domaine en cellules dans lesquelles les grandeurs seront localement constantes (Piecewise constant approximation).
L'objectif est ensuite de résoudre localement le système d'équations d'Euler à chaque interfaces de cellule pour obtenir l'évolution globale du système.
Chaque interfaces devient donc un problème de Riemann (cf figure \ref{fig:riemann}).
Considérant un système, régi par des équations de conservations, ayant comme état initial deux milieux homogènes de densité constante, séparé par une continuité, qu'elle sera son évolution?

%Nous aurons donc accès aux flux de matière et d'énergie entre les cellules pour pouvoir calculer l'état suivant  
%Connaissant l'état d'un système régit par des équation de conservation hyperbolique de type Euler a un instant donné.
%Le problème de Riemann consiste a considérer l’évolution d'un system d’équations différentielles à partir d'une condition initiale.
%En aillant l’état d'un système régis par des equations différentielles un instant donné, qu'elle sera sont évolution?

\begin{figure}
        \includegraphics[width=.95\linewidth]{img/02/riemann.pdf} 
        \caption[Problème de Riemann]{Problème de Riemann. Quelle sera l'évolution d'un système hydrodynamique considérant de telles conditions initiales.  
 		\label{fig:riemann}
 		}
\end{figure}

Il existe différents solveur de Riemann.
Contrairement à la résolution de l’équation de Poisson, il n'est plus possible d'utiliser une discrétisation à base de différence finie.

Par exemple, une différence finie centrée peut être décomposée en deux différence finies : 
\begin{equation}
\frac{d u}{dx} \approx \frac{u_{i+1}  - u_i}{\Delta x} 
\end{equation}

%Dans le premier cas, la discrétisation pourra s'écrire : 
La propagation d'une onde à la vitesse $a$ pourra être discrétisée en utilisant.

\begin{equation}
\frac{u_i^{t+1} - u_i^t }{\Delta t} - a \frac{u_{i+1}^t  - u_i^t}{\Delta x} = 0
\end{equation}

Ce type d'approche est dite explicite, car la solution du système au temps $t+1=t+\Delta t$ est obtenue à partir de l'état du système au temps $t$.
On parlera de schéma explicite en opposition au schéma implicite, qui lui utilisera en plus de l'état au temps $t$, l'état au temps $t+1$ pour déterminer l'évolution du système.
Ce dernier étant inconditionnellement stable mais largement plus complexe à implémenter dans notre cas.

On utilisera donc une approche explicite, mais celle-ci peux présenter des problèmes d'instabilités.
En fonction du signe de $a$, on parlera de méthode UPWIND ou DOWNWIND.
Il est possible de montrer à l'aide d'une analyse de von-Neumann (cf \cite{toro1999riemann}) que la méthode UPWIND est stable sous certaine condition, et que la méthode DOWNWIND est inconditionnellement instable.
Comme il n'est pas possible de connaître à l'avance le signe de $a$, dans les cas complexe que nous cherchons à traiter, la discrétisation par différences finies ne s'applique pas ici. 
On utilisera à la place une discrétisation par volumes finis.
Le principe est de ne plus calculer directement l'évolution des grandeurs au sein des cellules mais de passer par l'intermédiaire du calcul des flux entre elles.

%\subsection{Discrétisation du problème.}
%
%Contrairement à la résolution de l’équation de Poisson, il n'est plus possible d'utiliser une discrétisation des dérivées à l'aide d'un différence finie centrée.
%Nous allons rapidement voir pourquoi dans cette section.
%
%Une différence finie centrée peut être décomposée en deux différence finies : 
%\begin{equation}
%\frac{d u}{dx} \approx \frac{u_{i+1}  + u_i}{\Delta x} 
%\end{equation}
%
%\begin{equation}
%\frac{d u}{dx} \approx \frac{u_i  + u_{i+1}}{\Delta x} 
%\end{equation}
%
%Considérons que nous voulons résoudre l'équation :
%\begin{equation}
%\frac{du}{dt} + a\frac{du}{dx} = 0
%\end{equation}
%
%Dans le premier cas, la discrétisation pourra s'écrire : 
%%la propagation d'une onde a la vitesse $a$ pourra être discrétisée en utilisant.
%
%\begin{equation}
%\frac{u_i^{t+1} + u_i^t }{\Delta t}   +a \frac{u_{i+1}^t  + u_i^t}{\Delta x} = 0
%\end{equation}
%
%\begin{equation}
%u_i^{t+1}  = u_i^t +  c \left( u_{i+1}^t  + u_i^t \right) 
%\end{equation}
%
%ou : 
%
%\begin{equation}
%c= \frac{a \Delta t}{\Delta x},
%\end{equation}
%est le nombre de Courant
%
%A l'aide d'une analyse de von-Neumann (cf \cite{toro1999riemann}), on montre que la stabilité de ce schéma dépend du signe de a, la vitesse de propagation de l'onde.
%
%\begin{itemize}
%\item si a est positif, ce schéma est conditionnellement stable (la condition étant que la condition de Courant soient respectée : $0<c<1$) .
%Ce schema est appélé méthode UPWIND.
%
%\item A l'inverse on montre que que dans le cas de la seconde différence finie, le schéma est inconditionnellement instable. 
%Ce shema est appelée méthode DOWNWIND.
%\end{itemize}
%
%Seule la méthode upwind permet de suivre correctement la propagation d'onde.
%Le problème est qu'a trois dimension, il est impossible de respecter cette condition pour un système quelconque.
%% déterminer dans quelle direction se propage une onde quelconques.
%
%De plus il a été montré que cette méthode n'est pas conservative, et qu'elle était incapable de suivre les chocs (fortes discontinuités)
%


%\subsection{Méthode de Godunov}
%
%
%introduction aux volumes finis
%consiste 
%

%\subsection{discretisation}
\cite{MR0119433} a été le premier à introduire une méthode pour la résolution exacte de ce système.
%répondu à ce problème et introduit une méthode conservative.
Son approche consistait à estimer le flux aux interfaces des cellules et à discrétiser l'équation \ref{eq:conservation} de la manière suivante : 

\begin{equation}
\frac{ u^{t+1}_i - u^t_i }{\Delta t} - \frac{ F^t_{i+1/2} - F^t_{i-1/2} }{\Delta x} =0,
\label{eq:rad_solver}
\end{equation}

ou $F^t_{i+1/2}$ et $F^t_{i-1/2}$ sont les flux numérique inter-cellules, ou flux de Godunov, une estimations des flux physiques.
Tout la difficulté réside dans le calcul de ces flux aux interfaces. % : $F^t_{i+1/2}$
%TODO pb godunov
Différentes méthodes ont été développées, et celle retenue dans EMMA est la méthode HLL/HLLC.
La méthode de \ac{HLL} est une méthode au second ordre pour approximer les flux de Godunov dans le cas de la résolution en 3D des équations d'Euler.
La méthode \ac{HLL} a été modifiée par Toro 1992 et a donné lieu à la méthode HLLC, plus robuste.

Dans le problème de Riemann, les deux domaines ont des densités constantes, mais il est possible de considérer des schémas d'ordres supérieurs.
Par exemple le schéma \ac{MUSCL} introduit par \cite{1979JCoPh..32..101V},  considère une valeur évoluant linéairement dans la cellule. (cf figure\ref{fig:MUSCL}).
Pour éviter les cas menant à des pentes extrêmes, et dans le but de garder une solution monotone, dans EMMA la pente de cette interpolation est limitée par une méthode \textit{minmod}.
%TODO develeop

\begin{figure}
        \includegraphics[width=.95\linewidth]{img/02/MUSCL_minmod.pdf} 
        \caption[Méthode MUSCL]{Avec le \ac{MUSCL} la densité au sein des cellules est interpolée linéairement, ce qui améliore le calcul du flux aux interfaces.
        La pente est cependant limitée par la méthode du Minmod.
 		\label{fig:MUSCL}
 		}
\end{figure}



\subsection{Gestion du pas de temps}
\label{sec:dthydro}

Le pas de temps respecte la condition de \ac{CFL}, et s'exprime ici sous la forme :

\begin{equation}
\Delta t_{hydro} = C \frac{dx}{3V}
\end{equation}

où $C \in [0,1] $ est le nombre de Courant et $V = max(v + c_s)$ avec $v$ la vitesse du gaz et la vitesse du son $c_s = \sqrt{\gamma P/\rho}$ dans le cas d'un gaz parfais, une estimation de la vitesse de l'onde la plus rapide présente dans la simulation \citep{toro1999riemann}.
L'idée est que la vitesse de l'onde la plus rapide de la simulation ne doit pas parcourir plus d'une fraction de cellule par pas de temps, sans quoi la stabilité du modèle serait compromise.
Le pas de temps hydrodynamique est gouverné par la vitesse maximum du gaz (de l'ordre de $3000$km.s$^{-1}$) et sera en pratique près d'un ordre de grandeur plus faible que le pas de temps gravitationnel.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Rayonnement et énergie ionisante}
\label{sec:rad_solver}

L'objectif de cette section est de présenter les bases de la physique radiative, du transfert du rayonnement (RT) à son interaction avec les baryons.
Nous nous intéresserons ici uniquement au rayonnement capable de ioniser l'hydrogène.
Ce moteur physique se déroule en deux temps.
La première étape s'appelle le transport des photons et consiste à calculer la propagation du rayonnement.
La seconde étape sera le calcul de la "chimie", c'est à dire le calcul du couplage entre le rayonnement et le gaz.

\subsection{L'équation du transfert du rayonnement}

Dans cette section, nous verrons dans un premier temps le système d'équations à résoudre, puis dans un second temps, les méthodes de discrétisation.

L'équation du transfert du rayonnement lie l'évolution de l'intensité spécifique $I_\nu(\vec{x},\vec{n},t)$, au champ de sources $\eta_\nu(\vec{x},\vec{n},t)$, en fonction du coefficient d'absorption $\kappa_\nu(\vec{x},\vec{n},t)$ :
\begin{equation}
\frac{1}{c} \frac{\partial I_\nu}{\partial t} + \vec{n}\cdot \vec{\nabla} I_\nu = \eta_\nu - \kappa_\nu I_\nu 
\label{eq:rad}
\end{equation}

Le coefficient d'absorption s'exprime en fonction de la section efficace de photo-ionisation de l'hydrogène neutre $\sigma_\nu$ et de la densité d'hydrogène neutre $n_H$ :
\begin{equation}
\kappa_\nu(\vec{x},\vec{n},t) = \sigma_\nu n_H.
\end{equation}

Il existe trois grandes familles de codes de transfert de rayonnement.
\begin{itemize}

\item La première famille de méthodes est dite de "lancé de rayons".
Elle utilise une représentation proche de la physique de la lumière, et simule le rayonnement à l'aide de rayons se propageant dans l'espace.
Chaque source trace un certain nombre de rayons autour d'elle et l'équation de transfert du rayonnement est résolue le long de chaque ligne de visée.
% groupe de photon, qui vont se propager et interagir avec le milieu.
%L'équation de transfert du rayonnenment est résolue le long de la ligne de visée.
Dans ce type de méthode la vitesse de la lumière est considérée infinie.
Par exemple C$^2$RAY \citep{2006NewA...11..374M} est un représentant de cette famille.
Le principal inconvénient de cette méthode est que plus les sources sont nombreuses, plus le coût numérique augmente.

\item La seconde famille est dite de Monté Carlo.
Elle utilise également une représentation physique de la lumière mais cette fois ci ce ne sont plus des rayons, mais des paquets de photons qui se propagent dans l'espace.
Chaque source lance un certain nombre de groupes de photons, qui vont se propager et interagir avec le milieu.
L'avantage de cette méthode par rapport au lancé de rayons, est qu'elle autorise naturellement la diffusion.
Le coût numérique est encore dans ce cas, fonction du nombre de sources et sans un nombre important de paquets de photons, le bruit est important.
Les code LICORICE \citep{semelin_lyman-alpha_2007} ou CRASH \citep{2003MNRAS.345..379M} utilisent cette méthode.

\item La troisième famille est celle utilisée dans EMMA.
Elle revient à considérer la lumière comme un fluide. \citep{gnedin_multi-dimensional_2001, aubert_radiative_2008}.
Ces méthodes dites méthodes aux moments utiliseront donc les même concepts que le moteur hydrodynamique, mais avec un système d'équations différentes. 
EMMA utilise une approximation du moment au premier ordre, son moteur repose sur l'\textit{approximation M1} \citep{levermore_relating_1984, dubroca1999theoretical}.
Son principal avantage est que le coût numérique est indépendant du nombre de sources.
\end{itemize}


\subsection{Méthode des moments}
Les deux premiers moments (d'ordre 0 et 1) de l'équation \ref{eq:rad} s'exprime sous la forme:
\begin{equation}
\begin{cases}
\frac{ \partial N_\nu }{ \partial t } + \vec{\nabla} \cdot \vec{F}_\nu = -\kappa_\nu c  N_\nu + S_\nu,\\
\frac{ \partial \vec{F} }{ \partial t } + c^2 \vec{\nabla} P_\nu = -\kappa_\nu c \vec{F}_\nu ,
\end{cases}
\label{eq:densite_energie}
\end{equation}
avec:
$\vec{F}_\nu$ le flux radiatif, 
$P_\nu $ la pression radiative (sous forme tensorielle),
et $S_\nu = \dot{N}_\nu^* + \dot{N}_\nu^{rec}$ le taux d’émission de photon due aux sources $\dot{N}_\nu^*$ et à la recombinaison $ \dot{N}_\nu^{rec}$.
Ce type d'équations est comparable à des équations de conservation standard et leurs résolution utilisera les mêmes principes que ceux exposés dans la section \ref{sec:hydro}.

%TODO schéma explicite


\subsection{Relation de fermeture et approximation M1}

De la même manière que l'équation d'état des gaz parfait est utilisée pour fermer le système d'équations d'Euler (voir \ref{sec:hydro}).
Dans le cas du transfert du rayonnement, la fermeture du système se fait par l'intermédiaire de l’équation d’état :

\begin{equation}
 P_\nu = D N\nu ,
\label{eq:fermeture}
\end{equation}

ou $D$ est le tenseur d’Eddington et est approximé par le modèle M1 \citep{levermore_relating_1984}%,gonzalez2005} :

\begin{equation}
\begin{cases}

D = \frac{ 3\chi -1 }{2} \mathbb{1} + \frac{ 1 - \chi }{2} \vec{n} \otimes \vec{n} , \\
\\
\chi(\vec{f}_\nu) = \frac{ 3+4 |\vec{f}_\nu|^2 }{5+2\sqrt{4-3|\vec{f}_\nu|^2}} , \\
\\
\vec{f}_\nu = \frac{ \vec{F}_\nu }{c N\nu }  ,

\end{cases}
\label{eq:tenseur}
\end{equation}

Le flux réduit $\vec{f}_\nu$ quantifie l'anisotropie du rayonnement.
$\vec{f}_\nu$ varie entre $\vec{f}_\nu=0$ représentant le cas purement diffusif de rayonnement isotrope et $\vec{f}_\nu=1$ dans le cas d'un régime de transport purement directionnel.
Les valeurs intermédiaires permettant d'approximer la superposition de ces deux régimes.

\subsection{Gestion du pas de temps et vitesse de la lumière réduite}
\label{sec:RSLA}

La lumière étant extrêmement rapide, le suivi de son évolution demande un pas de temps réduit du fait de la condition de \ac{CFL} : $\Delta t_{rad} = C  \Delta x /c$.
D'une manière générale, le pas de temps radiatif est plusieurs ordres de grandeur plus petit que celui de l'hydrodynamique.
Or, dans les simulations cosmologiques, les processus entrant en jeu ont des vitesses très inférieures à celle de la lumière.
Par exemple, parmi les processus hydrodynamiques les plus rapides aux échelles considérées se trouvent les vents générés par les explosions de supernovæ, leurs vitesses sont de l'ordre de $3000 \mathrm{km.s}^{-1}$ soit deux ordres de grandeurs plus faibles que la vitesse de la lumière.
L'idée de l'approximation de la vitesse de la lumière réduite ou \ac{RSLA} est de diminuer la vitesse de la lumière dans le code tout en restant dans le régime ou la lumière reste plus rapide que les autre processus.
Pour se faire, on introduit $c_{num}$ la vitesse de la lumière numérique réduite en fonction de $c$ la vitesse de la lumière physique.
\begin{equation}
c_{num} = \tilde{c} \cdot{c},
\end{equation}
avec $\tilde{c}$ le facteur de proportionnalité. 
Par exemple, utiliser $\tilde{c}=0.1$ permet de réaliser 10 fois moins de pas de temps, et donc 10 fois moins de calcul.

J'ai mené une étude dans le but de quantifier l'influence de la vitesse de la lumière réduite sur la propagation des fronts d'ionisation.
Cette étude sera présentée en détails dans le chapitre \ref{sec:intre:zreio}.


\subsection{Groupes de photons}
\label{sec:groupedephotons}

Il n'est pas possible avec la méthode aux moments de considérer directement un spectre d'émission.
Le spectre doit être discrétisé, c'est-à-dire qu'il devra être découpé en un certain nombre de groupes, et chaque groupe disposera des caractéristiques moyennes de sa portion du spectre.
Le problème est que chaque groupe de photons devient un fluide à simuler a part entière et le coût numérique augmente rapidement avec le nombre de groupes. 
%Il est possible de choisir un nombre arbitraire de groupes, mais il faut prendre en compte que chaque groupe devient l'équivalent d'un fluide dont on veut suivre l'évolution.
%l'augmentation du nombre de groupe devient vite coûteux en terme de temps de calculs.
%Ce profil d’émission ionisante peut être découper en différents "groupe de photons" (cf section \ref{sec:groupedephotons}).

Prenons l'exemple d'un spectre d'émission arbitraire.
L’énergie moyenne d'un photon dans un groupe d'énergie comprissent entre $\nu_1$ et $\nu_2$ est calculée de la manière suivante:
\begin{equation}
<E> = \frac{1}{N} \int_{\nu_1}^{\nu_2} N_\nu h \nu d\nu
\end{equation}
et la section efficace d'interaction:
\begin{equation}
\sigma_E = \frac{1}{N<E>} \int_{\nu_1}^{\nu_2} \sigma_\nu N_\nu h \nu d\nu
\end{equation}

On prendra généralement la première borne au niveau de l'énergie d'ionisation de l'hydrogène : $\nu_1=13.6eV$.
Dans le cas où on ne considère qu'un seul groupe, les intégrations sont réalisées jusqu'à l'infini : $\nu_2= + \inf$.
J'ai également pu tester le cas de trois groupes, dans ce cas les bornes sont arbitrairement prisent aux niveaux des énergies d'ionisation de l'hélium : 
$\nu_2= 24.6 eV$, $\nu_3= 54.4 eV $, $\nu_4= + \inf$.

J'ai implémenté la possibilité de découper les groupes, non seulement en énergies, mais aussi en temps, car il est possible de considérer une évolution temporelle du spectre d'émission.
Dans ce cas l'énergie moyenne d'un groupe devient : 
\begin{equation}
<E> = \frac{1}{N}  \int_{t_1}^{t_2}  \int_{\nu_1}^{\nu_2} N_{(\nu,t)} h \nu d\nu dt
\end{equation}
Une opération identique est réalisée pour la section efficace.

Après de rapides tests, il s'avère que l'augmentation du nombre de groupes ne change pas la position ou la taille des bulles ionisée dans l'ensemble, mais apporte plus de nuances sur la définition des fronts par exemple.
Vu que le coût global du transfert du rayonnement augmente rapidement avec le nombre de groupe et dans le cas des résolutions considérées pendant ma thèse, l'augmentation du nombre de groupes ne s'est pas révélée pertinente.
% le ratio coût de calcul sur amélioration des prédictions ne s'est pas monté en faveur de l'augmentation du nombre de groupes
%De pluset vu les contraintes 
En pratique, je n'ai travaillé qu'avec un seul groupe de photons, considérant l'intégralité du spectre ionisant avec des énergies allant de 13.6 eV à $+\infty$.

\subsection{Couplage matière-rayonnement}
\label{sec:chimie}

La "chimie" fait le lien entre le moteur radiatif et le moteur hydrodynamique.
C'est à ce moment qu'est appliquée l'énergie apportée par le rayonnement au gaz et que le gaz va être chauffé par le rayonnement.
Le rayonnement aura différents impacts en fonction de la nature du gaz avec lequel il interagit: nous ne considérerons ici que la chimie de l'hydrogène.
C'est à se moment que la gestion du refroidissement du gaz à lieu et contrairement au transport, cette étape est non conservative.
Une partie des photons ionisants vont être absorbés par le gaz et réémis dans une partie du spectre non traitée ici.
Cette réémission va numériquement diminuer le bilan global d'énergie ionisante et être interprétée comme une perte.

Le système d'équations à résoudre lie la densité de photons, le flux de photons, l'état d'ionisation et l'énergie interne : 

\begin{equation}
\frac{dN}{dt} = S - c \sigma_N n_H N + \left( \alpha_A(T)  - \alpha_B(T) \right) x^2n_0^2
\end{equation}
\begin{equation}
\frac{dF}{dt} = - c \sigma_N n_H F
\end{equation}
\begin{equation}
\frac{dn_H}{dt} =  \left( \alpha_A(T)x^2  - \alpha_B(T)x (1-x) \right) n_0^2 - c \sigma_N n_HN
\end{equation}
\begin{equation}
\frac{de}{dt} = c n_H \Sigma_E N - \Lambda_{(n_0,x,T)}
\end{equation}

où $n_H$ est la densité d'atomes d'hydrogène (en nombre).
Les taux de réaction chimique $\alpha_A(T)$, $\alpha_B(T)$ et $\beta_(T)$ sont repris de tables de \cite{theuns_p^3m-sph_1998} et les sections efficace d'interactions de \cite{hui_equation_1997}.

Il est possible de considérer que toute l'émission de recombinaison est localement réabsorbée en forçant $\alpha_A(T) = \alpha_B(T)$.
Ceci est connu sous le nom de \ac{OTSA}.

Les processus chimiques agissant sur des échelles de temps courtes par rapport au transport des photons, le pas de temps sera plusieurs ordres de grandeurs plus faible.
En pratique, à chaque pas de temps radiatif, on effectuera un sous-cyclage sur le pas de temps chimique.
Après chaque pas de temps chimique, la variation d’énergie est calculée. 
Si celle ci est supérieure à 10\% ($\Delta E/E>0.1$), le pas de temps est divisée par 2 et l'étape courante est recalculée. (cf \cite{rosdahl_ramsesrt_2013}) 

Étant donné que les processus chimiques sont gérés de manière locale (ie ils ne dépendent pas de l'état des cellules voisines) et que la quantité de calcul est relativement importante, le portage du moteur chimique sur \ac{GPU} est très intéressant du point de vue accélération.

\clearpage
\section{Gestion de la cosmologie}
\label{sec:supercomobil}
%\label{sec:dtcosmo}

%On parlera de simulations cosmologiques lorsque l'e volume considéré est en expansion.

%Nous avons vu dans l'introduction à la physique de la reionisation que l'énergie noire représente la majore partie du contenu de l'univers (cf \ref{sec:dark_egy}) .
%Nous allons voir dans cette partie comme cette composante est traitée numériquement.
%Bien que nous ne sachions absolument pas ce que peux être physiquement l'énergie noire, nous en observons les effets : l'Univers est en expansion accélérée.
%Le moteur gérant l'énergie noire n'est pas a proprement parler un moteur numérique, mais plutôt d'un système d'unité. % servant a normaliser la physique.
%Il consiste a normaliser les grandeurs par une variable fonction du facteur d'expansion.

%L'intégration de la cosmologie, régissant le lien en le temps et le facteur d'expansion sera réalisé une fois au moment de l'initialisation du code (cf Eq. \ref{eq:scale_t}).
%Il en résultera une table, conservée en mémoire pendant toute l'exécution.
%Le facteur d'expansion sera alors interpolé dans cette table en fonction de l'avancement de la simulation.% (cf partie calcul du pas de temps) %TODO ref
%
%%Il existe deux possibilités pour modéliser l'expansion de l'univers à l'aide d'une grille.
%%La première consiste a considérer un élément de volume $dx$ de taille fixe, et au fur et a mesure que l'univers grandis, à y ajouter des éléments.
%%Le problème et que le coût numérique de la simulation croit, entre autre, avec le nombre d'éléments que l'on considère.
%
%L'expansion de l'univers et modélisée ici en faisant varier la taille des éléments de calcul avec le facteur d'expansion.
%On appellera les longueurs ainsi exprimées des longueurs comobile.
%
%\begin{equation}
%r=a r'
%\end{equation}
%
%ou $r$ représente une longueur en unités physique et $r'$ en unités comobile.
%Ainsi un segment de 10 Mpc physique de coté, pris aujourd'hui, aura une taille de 10 Mpc comobile (cMpc), mais aussi à redshift z=9 où sa taille physique ne sera plus que de 1 Mpc physique (pMpc ou juste Mpc).

Les moteurs présentés jusqu'ici ne sont valables que dans le cas d'un Univers statique.
L'expansion de l'Univers est modélisée ici en faisant varier la taille des éléments de calcul avec le facteur d'expansion.
On appellera les longueurs ainsi exprimées des longueurs comobile.
%\begin{equation}
%r=a \times r',
%\end{equation}
%où $r$ est une longueur physique, $r'$ une longueur comobile et $a$ la facteur d'expansion.
%De plus, on normalisera généralement les grandeurs que l'on considère:
%
%\begin{equation}
%r'=\tilde{r} \times r*,
%\end{equation}
%où $\tilde{r}$ est la longueur normalisée et $r*$ le facteur de normalisation.
La généralisation de ce principe à d'autre unités que la longueur est appelée système d'unités supercomobiles \citep{martel_convenient_1998}.
Les conversions utilisées sont présentées sur les tables \ref{tab:comobil} et \ref{tab:comobilfact}.
On remarquera que pour réaliser une simulation non cosmologique, où l'expansion n'est pas considérée, il suffit de fixer $a=1$.

\begin{table}
\begin{center}
\begin{tabular}{r l} \hline 
Longueur: & $\tilde{r}=\frac{r}{ar_*}$ \\ \hline 
Densité de matière: & $\tilde{\rho}=\frac{\rho a^3}{\rho_*}$ \\ \hline 
Vitesse: & $ \tilde{v}=\frac{av}{v_*}$ \\ \hline 
Pas de temps: & $\tilde{dt}=\frac{dt}{a^2t_*}$\\ \hline 
Densité d’énergie potentielle: & $\tilde{\Phi}=\frac{a^2 \Phi}{\Phi_*}$\\ \hline 
Pression: & $\tilde{p}=\frac{a^5 p}{p_*}$\\ \hline 
Densité d’énergie cinétique: & $\tilde{\epsilon}=\frac{a^2 \epsilon}{\epsilon_*}$\\ \hline 
Densité D’éléments: & $\tilde{N}=a^3 N r_*^3$\\ \hline 
Flux: & $\tilde{F}=a^4 r_*^2 t_* F$\\ \hline 
\end{tabular} 
\end{center}
\caption[Système d'unité supercomobile]{Passage du système d'unités physique vers le système d'unités supercomobiles.
\label{tab:comobil}
} 
\end{table}

\begin{table}
\begin{center}
\begin{tabular}{r l} \hline 
Longueur  & $r_*=L$\\ \hline 
Densité & $\rho_* = \bar{\rho} = \frac{3H_0^2 \Omega_m}{8\pi G}$\\ \hline 
Temps & $t_* = \frac{2}{H_0 \sqrt{\Omega_m}}$\\ \hline 
Vitesse & $v_* = \frac{r_*}{t_*}$\\ \hline 
Potentiel & $\Phi_* = \frac{r_*^2}{t_*^2} = v_*^2$\\ \hline 
Pression & $p_* = \frac{\rho_* r_*^2}{t_*^2} = \rho_* v_*^2$\\ \hline 
Énergie & $\epsilon_* = \frac{p_*}{\rho_*} = v_*^2$\\ \hline 
\end{tabular} 
\end{center}
\caption[Facteurs de normalisation]{Facteurs de normalisation des différents grandeurs physiques dans le système d'unités supercomobiles.
\label{tab:comobilfact}}
\end{table}


Pour assurer une certaine stabilité, l'évolution de la grille sera limitée d'un pas de temps à l'autre \citep{teyssier_cosmological_2002}.
La condition à respecter pour effectuer le calcul du pas de temps sera:
\begin{equation}
\frac{\delta a (\Delta t_{cosmo}) } {a} < \epsilon
\end{equation}


\section{Gestion du pas de temps}

D'une manière générale, le pas de temps global de la simulation sera le pas de temps le plus contraignant de toutes les physiques que l'on cherche à suivre et sera donc définie comme le minimum entre :

\begin{itemize}
\item le pas de temps cosmologique ($\Delta t_{cosmo}$ cf section \ref{sec:supercomobil}),
\item le pas de temps gravitationnel ($\Delta t_{pic}$ cf section \ref{sec:dtgrav}),
\item le pas de temps hydrodynamique ($\Delta t_{hydro}$ cf section \ref{sec:dthydro}),
\item le pas de temps radiatif ($\Delta t_{rad}$ cf section \ref{sec:RSLA}).
\end{itemize}

\subsection{Influence de l'AMR}

Sur une grille \ac{AMR}, le pas de temps n'est pas uniforme et dépend du niveau considéré, un niveau raffiné aura un pas de temps plus court que le niveau de base.
L'évolution entre les niveaux se fera en suivant le schéma présenté sur la figure \ref{fig:timestep}.
En première approximation, comme une cellule est raffinée en divisant par 2 chacune de ses dimensions, le pas de temps sera lui aussi divisé par 2, du fait de la condition de Courant.
Il faudra donc réaliser deux pas de temps fins (L+1) pour être synchronisé avec un niveau inférieur (L), et ce de manière récursive.
Ceci n'est vrai qu'à la condition que la physique résolue n'évolue pas avec la résolution spatiale.
En pratique, l'augmentation de résolution mène à une augmentation de la densité résolue, et généralement à un pas de temps hydrodynamique plus contraignant.
Ceci a pour effet de réduire le pas de temps d'un facteur supérieur à 2, et le pas de temps du niveau L+1 sera au final plus court que la moitié de celui du niveau L.
Il sera alors nécessaire de communiquer cette information sur les niveaux supérieurs pour effectuer la synchronisation.
De plus comme les niveaux fins évoluent avant les grossiers, les flux aux interfaces doivent être traités proprement : les cellules grossières "stockent" les flux provenant des niveaux fin avant  d'être complètement mis à jour.

\begin{figure}
\includegraphics[width=.8\linewidth]{img/02/tstep.png}
\caption[Pas de temps AMR]{Gestion du pas de temps en fonction des niveaux raffinées.
Les chiffres indiquent l'ordre d’exécution des calculs.
Un niveau évolue par pas de temps deux fois plus court que celui de son niveau supérieur.
\label{fig:timestep}}
\end{figure}


\subsection{Transport radiatif sur grille de base}
\label{sec:crta}

Le transport radiatif sur grille de base ou \ac{CRTA} est une technique visant à restreindre la résolution du champ de rayonnement dans le but d'en accélérer le calcul.
Dans le cas d'un couplage total entre les différents moteurs physiques, tous les moteurs évoluent au rythme le plus contraignant.
%il faut définir le plus petit pas de temps et faire évoluer 
Ce qui fait que, pour chaque pas de temps radiatif, il faut réaliser un pas de temps avec les autres moteurs physiques (cf panneau supérieur de la figure \ref{fig:CRTA}).
Dans notre cas, le rayonnement est plusieurs ordres de grandeurs plus contraignante que l'hydrodynamique ou la gravitation.
Donc le nombre de pas de temps hydrodynamiques et gravitationnels nécessaires sont largement surestimés, et le coût numérique explose.

Dans le cas de la \ac{CRTA}, le transport des photons n'est réalisé que sur la grille de base, et non sur les niveaux raffinées (cf panneau inférieur de la figure \ref{fig:CRTA}), sur lesquels l'hydrodynamique est considérée comme "gelée" lors du calcul.
Ce qui a pour effet d'augmenter la taille du pas de temps radiatif, du fait de la condition de Courant.
La densité de photon calculée sur la grille de base est ensuite projeté sur les niveaux raffinés, ces derniers ressentant localement un champ uniforme de rayonnement.
Les concepts précis de la \ac{CRTA} étant assez technique, j'invite le lecteur à se référer à \cite{aubert_emma:_2015} pour une explication plus détaillée.

Actuellement, la \ac{CRTA} n'est possible que sur le niveau de base.
Un amélioration possible serait de pouvoir définir le niveaux de projection de le rayonnement pour pouvoir, en fonction des besoins, faire varier le poids de le rayonnement dans le calcul.


\begin{figure}
\includegraphics[width=.95\linewidth]{img/02/revz_crad_std.png}
\includegraphics[width=.95\linewidth]{img/02/revz_crad.png}
\caption[CRTA]{Gestion de l'évolution du rayonnement dans le cas de la \ac{CRTA}.
En noir les moteurs dynamiques, en rouge le transport des photons, en bleu la chimie.
Le transport des photons n'est réalisé que sur la grille de niveau de base.
Le nombre d'appels aux moteurs hydrodynamique et gravitationnel est significativement réduit. 
\label{fig:CRTA}}
\end{figure}

